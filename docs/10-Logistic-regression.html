<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Logistic Regression – ETC1000 2026</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./09-Classification-and-prediction.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-c27fdc8e5b00b532d2d5a75ada188648.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-b9e11ad5a37ead2aabff839d95ae3857.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-c27fdc8e5b00b532d2d5a75ada188648.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">

<script src="site_libs/tabwid-1.1.3/tabwid.js"></script>

<script src="site_libs/font-awesome-6.7.2/js/script.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<link rel="stylesheet" href="include/webex.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./10-Logistic-regression.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">ETC1000 2026</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="./ETC1000-2026.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Introduction-to-statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics &amp; Categorical Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Analysing-numerical-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Analysing Numerical Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Understanding-uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Understanding uncertainty</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-Models-of-relationships-between-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Models of relationships between data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Multiple-regression-and-hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-More-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">More Regression Concepts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-Introduction-to-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-The-tidyverse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">The tidyverse</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-Classification-and-prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Classification and Prediction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-Logistic-regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">10.1</span> Introduction</a></li>
  <li><a href="#log-odds" id="toc-log-odds" class="nav-link" data-scroll-target="#log-odds"><span class="header-section-number">10.2</span> Log-odds</a></li>
  <li><a href="#recap-probability-and-the-complement-probability" id="toc-recap-probability-and-the-complement-probability" class="nav-link" data-scroll-target="#recap-probability-and-the-complement-probability"><span class="header-section-number">10.3</span> Recap: Probability and the Complement Probability</a>
  <ul class="collapse">
  <li><a href="#probability" id="toc-probability" class="nav-link" data-scroll-target="#probability"><span class="header-section-number">10.3.1</span> Probability</a></li>
  <li><a href="#complement-probability" id="toc-complement-probability" class="nav-link" data-scroll-target="#complement-probability"><span class="header-section-number">10.3.2</span> Complement Probability</a></li>
  </ul></li>
  <li><a href="#odds-and-the-odds-ratio" id="toc-odds-and-the-odds-ratio" class="nav-link" data-scroll-target="#odds-and-the-odds-ratio"><span class="header-section-number">10.4</span> Odds and the Odds Ratio</a>
  <ul class="collapse">
  <li><a href="#odds" id="toc-odds" class="nav-link" data-scroll-target="#odds"><span class="header-section-number">10.4.1</span> Odds</a></li>
  <li><a href="#odds-ratio" id="toc-odds-ratio" class="nav-link" data-scroll-target="#odds-ratio"><span class="header-section-number">10.4.2</span> Odds Ratio</a></li>
  </ul></li>
  <li><a href="#the-logit-function" id="toc-the-logit-function" class="nav-link" data-scroll-target="#the-logit-function"><span class="header-section-number">10.5</span> The Logit Function</a>
  <ul class="collapse">
  <li><a href="#the-problem-with-modeling-probabilities-directly" id="toc-the-problem-with-modeling-probabilities-directly" class="nav-link" data-scroll-target="#the-problem-with-modeling-probabilities-directly"><span class="header-section-number">10.5.1</span> The Problem With Modeling Probabilities Directly</a></li>
  <li><a href="#from-probabilities-to-odds-and-log-odds-the-logit" id="toc-from-probabilities-to-odds-and-log-odds-the-logit" class="nav-link" data-scroll-target="#from-probabilities-to-odds-and-log-odds-the-logit"><span class="header-section-number">10.5.2</span> From probabilities to odds and log-odds (the logit)</a></li>
  </ul></li>
  <li><a href="#the-anti-logit-inverse-logit" id="toc-the-anti-logit-inverse-logit" class="nav-link" data-scroll-target="#the-anti-logit-inverse-logit"><span class="header-section-number">10.6</span> The Anti-Logit (Inverse Logit)</a>
  <ul class="collapse">
  <li><a href="#the-anti-logit-function" id="toc-the-anti-logit-function" class="nav-link" data-scroll-target="#the-anti-logit-function"><span class="header-section-number">10.6.1</span> The anti-logit function</a></li>
  </ul></li>
  <li><a href="#the-binomial-distribution" id="toc-the-binomial-distribution" class="nav-link" data-scroll-target="#the-binomial-distribution"><span class="header-section-number">10.7</span> The Binomial Distribution</a>
  <ul class="collapse">
  <li><a href="#bernoulli-trials" id="toc-bernoulli-trials" class="nav-link" data-scroll-target="#bernoulli-trials"><span class="header-section-number">10.7.1</span> Bernoulli Trials</a></li>
  <li><a href="#from-bernoulli-to-binomial" id="toc-from-bernoulli-to-binomial" class="nav-link" data-scroll-target="#from-bernoulli-to-binomial"><span class="header-section-number">10.7.2</span> From Bernoulli to Binomial</a></li>
  <li><a href="#interpreting-the-binomial-distribution" id="toc-interpreting-the-binomial-distribution" class="nav-link" data-scroll-target="#interpreting-the-binomial-distribution"><span class="header-section-number">10.7.3</span> Interpreting the Binomial Distribution</a></li>
  <li><a href="#mean-and-variability" id="toc-mean-and-variability" class="nav-link" data-scroll-target="#mean-and-variability"><span class="header-section-number">10.7.4</span> Mean and Variability</a></li>
  <li><a href="#why-the-binomial-distribution-matters-for-logistic-regression" id="toc-why-the-binomial-distribution-matters-for-logistic-regression" class="nav-link" data-scroll-target="#why-the-binomial-distribution-matters-for-logistic-regression"><span class="header-section-number">10.7.5</span> Why the Binomial Distribution Matters for Logistic Regression</a></li>
  </ul></li>
  <li><a href="#extending-to-r-from-lm-to-glm" id="toc-extending-to-r-from-lm-to-glm" class="nav-link" data-scroll-target="#extending-to-r-from-lm-to-glm"><span class="header-section-number">10.8</span> Extending to R: From <code>lm()</code> to <code>glm()</code></a>
  <ul class="collapse">
  <li><a href="#generalised-linear-models-glms" id="toc-generalised-linear-models-glms" class="nav-link" data-scroll-target="#generalised-linear-models-glms"><span class="header-section-number">10.8.1</span> Generalised Linear Models (GLMs)</a></li>
  <li><a href="#logistic-regression-in-r" id="toc-logistic-regression-in-r" class="nav-link" data-scroll-target="#logistic-regression-in-r"><span class="header-section-number">10.8.2</span> Logistic Regression in R</a></li>
  <li><a href="#comparing-lm-to-glm" id="toc-comparing-lm-to-glm" class="nav-link" data-scroll-target="#comparing-lm-to-glm"><span class="header-section-number">10.8.3</span> Comparing <code>lm()</code> to <code>glm()</code></a></li>
  </ul></li>
  <li><a href="#a-worked-example" id="toc-a-worked-example" class="nav-link" data-scroll-target="#a-worked-example"><span class="header-section-number">10.9</span> A worked Example</a>
  <ul class="collapse">
  <li><a href="#making-predictions" id="toc-making-predictions" class="nav-link" data-scroll-target="#making-predictions"><span class="header-section-number">10.9.1</span> Making Predictions</a></li>
  <li><a href="#explaining-the-regression-coefficients" id="toc-explaining-the-regression-coefficients" class="nav-link" data-scroll-target="#explaining-the-regression-coefficients"><span class="header-section-number">10.9.2</span> Explaining the Regression Coefficients</a></li>
  <li><a href="#multiple-predictors" id="toc-multiple-predictors" class="nav-link" data-scroll-target="#multiple-predictors"><span class="header-section-number">10.9.3</span> Multiple Predictors</a></li>
  </ul></li>
  <li><a href="#practice-with-r" id="toc-practice-with-r" class="nav-link" data-scroll-target="#practice-with-r"><span class="header-section-number">10.10</span> Practice with R</a>
  <ul class="collapse">
  <li><a href="#download-the-data" id="toc-download-the-data" class="nav-link" data-scroll-target="#download-the-data"><span class="header-section-number">10.10.1</span> Download the data</a></li>
  <li><a href="#load-the-data-in-rstudio" id="toc-load-the-data-in-rstudio" class="nav-link" data-scroll-target="#load-the-data-in-rstudio"><span class="header-section-number">10.10.2</span> Load the data in RStudio</a></li>
  <li><a href="#load-the-tidyverse" id="toc-load-the-tidyverse" class="nav-link" data-scroll-target="#load-the-tidyverse"><span class="header-section-number">10.10.3</span> Load the tidyverse</a></li>
  <li><a href="#inspect-the-data" id="toc-inspect-the-data" class="nav-link" data-scroll-target="#inspect-the-data"><span class="header-section-number">10.10.4</span> Inspect the data</a></li>
  <li><a href="#training-and-testing-sets" id="toc-training-and-testing-sets" class="nav-link" data-scroll-target="#training-and-testing-sets"><span class="header-section-number">10.10.5</span> Training and Testing sets</a></li>
  <li><a href="#building-the-model" id="toc-building-the-model" class="nav-link" data-scroll-target="#building-the-model"><span class="header-section-number">10.10.6</span> Building the model</a></li>
  <li><a href="#making-predictions-1" id="toc-making-predictions-1" class="nav-link" data-scroll-target="#making-predictions-1"><span class="header-section-number">10.10.7</span> Making predictions</a></li>
  <li><a href="#combining-actual-and-predictions" id="toc-combining-actual-and-predictions" class="nav-link" data-scroll-target="#combining-actual-and-predictions"><span class="header-section-number">10.10.8</span> Combining Actual and Predictions</a></li>
  <li><a href="#reorder-factor-levels-optional" id="toc-reorder-factor-levels-optional" class="nav-link" data-scroll-target="#reorder-factor-levels-optional"><span class="header-section-number">10.10.9</span> Reorder factor levels (optional)</a></li>
  <li><a href="#confusion-matrix" id="toc-confusion-matrix" class="nav-link" data-scroll-target="#confusion-matrix"><span class="header-section-number">10.10.10</span> Confusion Matrix</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">10.11</span> Summary</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">10.12</span> Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Logistic Regression</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<p>By the end of this chapter, you should be able to:</p>
<ol type="1">
<li>Explain why the linear probability model (LPM) can produce invalid predictions for binary outcomes and describe the key limitations of using lm() for classification.</li>
<li>Convert between probabilities, odds, and log-odds (logits), and interpret what different values on each scale mean.</li>
<li>Use the logit and anti-logit transformations to move between the probability scale and the log-odds scale.</li>
<li>Describe the shape and key properties of the logistic (sigmoid) curve, including why probability changes are non-linear even when log-odds change linearly.</li>
<li>Fit a logistic regression model in R using glm() and obtain predicted probabilities using predict().</li>
<li>Interpret logistic regression coefficients in terms of odds and odds ratios, and explain what an odds ratio means in context.</li>
<li>Apply a classification threshold (e.g., 0.5) to convert predicted probabilities into predicted classes and evaluate performance using a confusion matrix.</li>
</ol>
</div>
</div>
<center>
<div class="cell enlarge-image">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="images/Covers/cover10.png" class="img-fluid figure-img" width="2098"></p>
</figure>
</div>
</div>
</div>
</center>
<section id="introduction" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">10.1</span> Introduction</h2>
<p>In the previous chapter, we explored classification and prediction, focusing on how to use a linear probability model (LPM) to handle categorical outcomes. In this approach, we treated the outcome (for example, win vs.&nbsp;lose, or success vs.&nbsp;failure) as a binary variable and fitted a standard linear regression model. Using this model, we generated predicted values and then applied a classification rule (such as assigning outcomes greater than 0.5 to “success” and those less than 0.5 to “failure”). While this approach gave us a first glimpse into prediction for categorical outcomes, we also discussed its limitations:</p>
<ul>
<li>Predicted probabilities from the LPM can fall outside the valid range of 0 to 1.</li>
<li>The relationship between predictors and the outcome is assumed to be linear, which is often unrealistic for probability data.</li>
<li>The errors in the model are heteroscedastic (the variance changes with the level of the predictors), violating a key assumption of linear regression.</li>
</ul>
<p>These issues make the linear probability model less reliable, especially when we want to use the model for decision-making or inference.</p>
<p>In this chapter, we will learn about logistic regression, a method specifically designed for categorical outcomes. Logistic regression overcomes the key problems of the linear probability model by ensuring that predicted probabilities always fall between 0 and 1 and by modelling the relationship between predictors and the outcome in a more flexible, non-linear way. It is one of the most widely used models in data science, business, and the social and health sciences for analysing binary and categorical data.</p>
</section>
<section id="log-odds" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="log-odds"><span class="header-section-number">10.2</span> Log-odds</h2>
<p>Logistic regression models the log of the odds (log-odds) as a linear function of predictors. By working with odds, rather than probabilities directly, we can map any probability between 0 and 1 onto the entire real number line. This transformation removes the hard boundaries that caused problems for the linear probability model and allows us to use familiar linear modelling ideas in a setting where the outcome is binary.</p>
<p>This also changes how we interpret model coefficients. Instead of describing changes in probability, coefficients in a logistic regression describe how the odds of an outcome change when a predictor increases. While this may feel less intuitive at first, odds have a key advantage: they respond smoothly and consistently across the entire range of possible outcomes. Small changes near probabilities of 0 or 1 behave differently from changes near 0.5, and odds naturally capture this non-linear behaviour.</p>
<p>In the sections that follow, we will build up this idea step by step—first by understanding probability, odds and log-odds on their own, and then by showing how they form the foundation of a regression model that is better suited to classification problems than the linear probability model.</p>
</section>
<section id="recap-probability-and-the-complement-probability" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="recap-probability-and-the-complement-probability"><span class="header-section-number">10.3</span> Recap: Probability and the Complement Probability</h2>
<p>Before we dive into logistic regression, it is useful to revisit some core probability concepts that underpin the model. Logistic regression is not built directly on probabilities, but instead on odds and log-odds (logits). Understanding these ideas will help us see why logistic regression is structured the way it is.</p>
<section id="probability" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="probability"><span class="header-section-number">10.3.1</span> Probability</h3>
<p>The probability of an event measures the likelihood that the event will occur. It is always a value between 0 and 1:</p>
<p><span class="math display">\[P(\text{Event})=\frac{\text{N outcomes where Event occurs}}{\text{Total N of possible outcomes}}\]</span></p>
<p>For example, the probability of drawing a clubs card from a standard deck of playing cards would be:</p>
<center>
<img src="images/Chapter 10/01.Prob.png" class="img-fluid">
</center>
</section>
<section id="complement-probability" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="complement-probability"><span class="header-section-number">10.3.2</span> Complement Probability</h3>
<p>The complement probability (<span class="math inline">\(A^c\)</span> or <span class="math inline">\(A'\)</span>) represents the likelihood that the event does not occur. Using our example from above:</p>
<center>
<img src="images/Chapter 10/02.CompProb.png" class="img-fluid">
</center>
<p>This can also be expressed as:</p>
<p><span class="math display">\[
\begin{aligned}
P(\text{not clubs}) &amp;= 1-P(\text{clubs}) \\
   &amp;= 1 - \frac{13}{52} \\
   &amp;= \frac{39}{52} \\
   &amp;= \frac{3}{4}
\end{aligned}
\]</span></p>
</section>
</section>
<section id="odds-and-the-odds-ratio" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="odds-and-the-odds-ratio"><span class="header-section-number">10.4</span> Odds and the Odds Ratio</h2>
<p>While probabilities are intuitive and easy to interpret, they are not the only way to describe uncertainty. Another closely related way of expressing likelihood is through odds. Instead of measuring how likely an event is to occur on a 0–1 scale, odds compare the chance that an event occurs to the chance that it does not occur.</p>
<section id="odds" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="odds"><span class="header-section-number">10.4.1</span> Odds</h3>
<p>The odds of an event are the ratio of the probability the event happens to the probability it does not happen (which are two terms we just recapped in the section above):</p>
<p><span class="math display">\[
\begin{aligned}
Odds(\text{Event}) &amp;= \frac{P(\text{Event})}{1-P(\text{Event})} \\
\end{aligned}
\]</span></p>
<p>So, in our current example:</p>
<center>
<img src="images/Chapter 10/03.Odds.png" class="img-fluid">
</center>
<p>This means the odds of drawing a clubs card are 1 to 3.</p>
</section>
<section id="odds-ratio" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="odds-ratio"><span class="header-section-number">10.4.2</span> Odds Ratio</h3>
<p>An odds ratio (OR) compares the odds of an event occurring in one group to the odds of it occurring in another group:</p>
<p><span class="math display">\[OR=\frac{Odds(A)}{Odds(B)}\]</span> For example, suppose two basketball teams have the following free-throw success probabilities:</p>
<ul>
<li><span class="math inline">\(P(\text{Team}_A)=0.80\)</span></li>
<li><span class="math inline">\(P(\text{Team}_B)=0.60\)</span></li>
</ul>
<p>The first step is to calculate the odds for each team:</p>
<ul>
<li><span class="math inline">\(Odds(A)=\frac{0.80}{1-0.80}=4\)</span></li>
<li><span class="math inline">\(Odds(B)=\frac{0.60}{1-0.60}=1.5\)</span></li>
</ul>
<p>Then the Odds Ratio (OR) would be:</p>
<p><span class="math display">\[OR=\frac{4}{1.5}=2.67\]</span></p>
<p>This means Team A’s odds of scoring a free throw are 2.67 times higher than Team B’s.</p>
</section>
</section>
<section id="the-logit-function" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="the-logit-function"><span class="header-section-number">10.5</span> The Logit Function</h2>
<p>Logistic regression is built on the idea that, rather than modelling probability directly, we model the log of the odds of an event occurring. This transformation is called the logit function, and it solves the major limitations we faced with the linear probability model.</p>
<section id="the-problem-with-modeling-probabilities-directly" class="level3" data-number="10.5.1">
<h3 data-number="10.5.1" class="anchored" data-anchor-id="the-problem-with-modeling-probabilities-directly"><span class="header-section-number">10.5.1</span> The Problem With Modeling Probabilities Directly</h3>
<p>Recall that a probability, <span class="math inline">\(p\)</span>, always lies between 0 and 1. But a linear regression model does not respect this restriction — it can produce predictions less than 0 or greater than 1. For example, if we tried to model “probability of winning a game” with a linear function like:</p>
<p><span class="math display">\[p=\beta_0+\beta_1X\]</span></p>
<p>there is no guarantee that the predicted p will stay in the 0–1 range.</p>
<center>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="10-Logistic-regression_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</center>
<p>We need a function that:</p>
<ol type="1">
<li>Keeps predictions in the range (0, 1).</li>
<li>Still allows us to use a linear equation for estimation and interpretation.</li>
</ol>
<p>This is where the logit function comes in.</p>
</section>
<section id="from-probabilities-to-odds-and-log-odds-the-logit" class="level3" data-number="10.5.2">
<h3 data-number="10.5.2" class="anchored" data-anchor-id="from-probabilities-to-odds-and-log-odds-the-logit"><span class="header-section-number">10.5.2</span> From probabilities to odds and log-odds (the logit)</h3>
<p>A probability <span class="math inline">\(p\)</span> is always between 0 and 1, but a linear model can produce predictions outside that range. To address this, logistic regression <strong>does not model</strong> <span class="math inline">\(p\)</span> directly. Instead, it models a transformed version of <span class="math inline">\(p\)</span> that can take any real value.</p>
<p><strong>Step 1 — Convert a probability to odds</strong></p>
<p>The <strong>odds</strong> of an event compare “success” to “failure”:</p>
<p><span class="math display">\[
\text{Odds} = \frac{p}{1-p}
\]</span></p>
<p>You can read odds as:</p>
<blockquote class="blockquote">
<p>“How many times more likely is success than failure?”</p>
</blockquote>
<p>Some examples:</p>
<ul>
<li><p>If <span class="math inline">\(p = 0.50\)</span>,</p>
<p><span class="math display">\[
\text{Odds} = \frac{0.50}{1-0.50} = \frac{0.50}{0.50} = 1
\]</span></p>
<p>Odds = 1 means success and failure are equally likely (a <strong>1:1</strong> ratio).</p></li>
<li><p>If <span class="math inline">\(p = 0.80\)</span>,</p>
<p><span class="math display">\[
\text{Odds} = \frac{0.80}{1-0.80} = \frac{0.80}{0.20} = 4
\]</span></p>
<p>Odds = 4 means success is <strong>four times as likely</strong> as failure (a <strong>4:1</strong> ratio).</p></li>
<li><p>If <span class="math inline">\(p = 0.20\)</span>,</p>
<p><span class="math display">\[
\text{Odds} = \frac{0.20}{1-0.20} = \frac{0.20}{0.80} = 0.25
\]</span></p>
<p>Odds = 0.25 means success is <strong>one quarter as likely</strong> as failure — equivalently, failure is <strong>four times as likely</strong> as success (a <strong>1:4</strong> ratio).</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>Key property:</strong> odds can take any value from <span class="math inline">\(0\)</span> to <span class="math inline">\(+\infty\)</span>.</p>
</blockquote>
<p>This is an improvement over probabilities, but odds are still <strong>bounded below at 0</strong> and are often <strong>highly skewed</strong>, which makes them unsuitable for direct linear modelling.</p>
<p><strong>Step 2 — Take the log of the odds (log-odds)</strong></p>
<p>To remove the lower bound and spread values more symmetrically, we take the natural logarithm of the odds:</p>
<p><span class="math display">\[
\text{logit}(p) = \ln\left(\frac{p}{1-p}\right)
\]</span></p>
<p>This is known as the <strong>logit</strong> (or <strong>log-odds</strong>) transformation.</p>
<p>This transformation has several important properties:</p>
<ul>
<li><p>As <span class="math inline">\(p \rightarrow 0\)</span>, <span class="math inline">\(\text{logit}(p) \rightarrow -\infty\)</span></p></li>
<li><p>As <span class="math inline">\(p \rightarrow 1\)</span>, <span class="math inline">\(\text{logit}(p) \rightarrow +\infty\)</span></p></li>
<li><p>When <span class="math inline">\(p = 0.5\)</span>,</p>
<p><span class="math display">\[
\text{logit}(0.5) = \ln\left(\frac{0.5}{0.5}\right) = \ln(1) = 0
\]</span></p></li>
</ul>
<p>So:</p>
<ul>
<li>Negative logit values correspond to probabilities <strong>below 0.5</strong></li>
<li>Positive logit values correspond to probabilities <strong>above 0.5</strong></li>
<li>A logit of 0 corresponds to a <strong>50–50 chance</strong></li>
</ul>
<p>The logit transformation maps the probability range <span class="math inline">\((0,1)\)</span> onto the entire real line <span class="math inline">\((-\infty, +\infty)\)</span>. This allows us to use a linear model for the transformed outcome, while still guaranteeing that predicted probabilities (after transforming back) remain between 0 and 1.</p>
<p><strong>Step 3 — The logistic regression model</strong></p>
<p>In logistic regression, we assume that the <strong>logit of the probability</strong> is a linear function of the predictors:</p>
<p><span class="math display">\[
\text{logit}(p) = \ln\left(\frac{p}{1-p}\right)
= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k
\]</span></p>
<p>This looks just like an ordinary linear regression equation — except the left-hand side is not the outcome itself, but the <strong>log-odds of the probability of the outcome</strong>.</p>
<p>In words:</p>
<blockquote class="blockquote">
<p>Logistic regression assumes that the <strong>log-odds of success change linearly with the predictors</strong>.</p>
</blockquote>
<p>By modelling log-odds rather than probabilities directly, logistic regression avoids impossible predictions and provides a principled way to connect linear models with binary outcomes.</p>
</section>
</section>
<section id="the-anti-logit-inverse-logit" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="the-anti-logit-inverse-logit"><span class="header-section-number">10.6</span> The Anti-Logit (Inverse Logit)</h2>
<p>In the previous section, we introduced the <strong>logit function</strong>, which transforms a probability <span class="math inline">\(p\)</span> into the <strong>log-odds of success</strong>. This transformation is what makes logistic regression possible, because it allows us to model a linear relationship on an unbounded scale.</p>
<p>However, once we have estimated a logistic regression model, we usually do <strong>not</strong> want to interpret results in terms of log-odds. Probabilities are far more intuitive. To convert model outputs back to probabilities, we use the <strong>anti-logit</strong> (or <strong>inverse logit</strong>) function.</p>
<section id="the-anti-logit-function" class="level3" data-number="10.6.1">
<h3 data-number="10.6.1" class="anchored" data-anchor-id="the-anti-logit-function"><span class="header-section-number">10.6.1</span> The anti-logit function</h3>
<p>The anti-logit function converts log-odds, denoted by <span class="math inline">\(\eta\)</span>, back into a probability:</p>
<p><span class="math display">\[
p = \frac{e^{\eta}}{1 + e^{\eta}}
\]</span></p>
<p>Here, <span class="math inline">\(\eta\)</span> represents the linear predictor from the logistic regression model:</p>
<p><span class="math display">\[
\eta = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k
\]</span></p>
<p>This transformation ensures that, regardless of the value of <span class="math inline">\(\eta\)</span>, the resulting probability is always valid.</p>
<section id="properties-of-the-anti-logit" class="level4" data-number="10.6.1.1">
<h4 data-number="10.6.1.1" class="anchored" data-anchor-id="properties-of-the-anti-logit"><span class="header-section-number">10.6.1.1</span> Properties of the Anti-Logit</h4>
<p>The anti-logit function has several important properties that make logistic regression well suited for modelling binary outcomes.</p>
</section>
<section id="range-restriction" class="level4" data-number="10.6.1.2">
<h4 data-number="10.6.1.2" class="anchored" data-anchor-id="range-restriction"><span class="header-section-number">10.6.1.2</span> Range restriction</h4>
<p>No matter what value <span class="math inline">\(\eta\)</span> takes (from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(+\infty\)</span>), the resulting probability always satisfies:</p>
<p><span class="math display">\[
0 &lt; p &lt; 1
\]</span></p>
<p>This guarantees that predicted probabilities never fall outside the valid range.</p>
</section>
<section id="s-shaped-sigmoid-curve" class="level4" data-number="10.6.1.3">
<h4 data-number="10.6.1.3" class="anchored" data-anchor-id="s-shaped-sigmoid-curve"><span class="header-section-number">10.6.1.3</span> S-shaped (sigmoid) curve</h4>
<p>When plotted against <span class="math inline">\(\eta\)</span>, the anti-logit function produces an <strong>S-shaped curve</strong>, also known as the <strong>logistic</strong> or <strong>sigmoid</strong> curve.</p>
<p>Its behaviour at key values is:</p>
<ul>
<li><p>As <span class="math inline">\(\eta \rightarrow -\infty\)</span>, <span class="math inline">\(p \rightarrow 0\)</span></p></li>
<li><p>As <span class="math inline">\(\eta \rightarrow +\infty\)</span>, <span class="math inline">\(p \rightarrow 1\)</span></p></li>
<li><p>At <span class="math inline">\(\eta = 0\)</span>,</p>
<p><span class="math display">\[
p = \frac{e^0}{1 + e^0} = \frac{1}{2} = 0.5
\]</span></p></li>
</ul>
</section>
<section id="symmetry" class="level4" data-number="10.6.1.4">
<h4 data-number="10.6.1.4" class="anchored" data-anchor-id="symmetry"><span class="header-section-number">10.6.1.4</span> Symmetry</h4>
<p>The logistic curve is symmetric around <span class="math inline">\(\eta = 0\)</span>.<br>
This point corresponds to a probability of 0.5 and represents the location where the curve is steepest.</p>
<p>Together, these properties explain why logistic regression is so powerful: probabilities change smoothly with predictor values while <strong>never straying outside valid bounds</strong>.</p>
<p>Graphically, the anti-logit transformation produces the <strong>logistic curve</strong>, which has three key regions:</p>
<ul>
<li>At very low values of <span class="math inline">\(\eta\)</span>, the curve flattens near 0<br>
</li>
<li>Around <span class="math inline">\(\eta = 0\)</span>, the curve is steepest, meaning small changes in predictors have the <strong>largest effect on probability</strong></li>
<li>At very high values of <span class="math inline">\(\eta\)</span>, the curve flattens near 1</li>
</ul>
<center>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="10-Logistic-regression_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</center>
<p>This behaviour reflects many real-world processes. Once an outcome is almost impossible or almost certain, small changes in predictors have little impact. Logistic regression naturally captures this pattern while still allowing us to use a linear model on the log-odds scale.</p>
</section>
</section>
</section>
<section id="the-binomial-distribution" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="the-binomial-distribution"><span class="header-section-number">10.7</span> The Binomial Distribution</h2>
<p>So far, we have focused on modelling <strong>binary outcomes</strong> — events that either occur or do not occur (such as pass/fail, win/loss, success/failure). To understand how logistic regression connects to probability theory, we now introduce the <strong>binomial distribution</strong>.</p>
<p>The binomial distribution describes the probability of observing a certain number of successes when:</p>
<ol type="1">
<li>Each trial has only two possible outcomes (success or failure),</li>
<li>The probability of success, <span class="math inline">\(p\)</span>, is the same for every trial,</li>
<li>The trials are independent.</li>
</ol>
<p>These conditions closely match many real-world situations, such as:</p>
<ul>
<li>Passing or failing an exam question,</li>
<li>Making or missing a free throw,</li>
<li>Winning or losing a game.</li>
</ul>
<section id="bernoulli-trials" class="level3" data-number="10.7.1">
<h3 data-number="10.7.1" class="anchored" data-anchor-id="bernoulli-trials"><span class="header-section-number">10.7.1</span> Bernoulli Trials</h3>
<p>Before introducing the binomial distribution, it is helpful to start with the simplest case: a <strong>Bernoulli trial</strong>.</p>
<p>A Bernoulli trial is a single experiment with:</p>
<ul>
<li>Probability of success <span class="math inline">\(p\)</span>,</li>
<li>Probability of failure <span class="math inline">\(1 - p\)</span>.</li>
</ul>
<p>We often code outcomes as:</p>
<ul>
<li><span class="math inline">\(Y = 1\)</span> for success,</li>
<li><span class="math inline">\(Y = 0\)</span> for failure.</li>
</ul>
<p>In this setting:</p>
<ul>
<li><span class="math inline">\(P(Y = 1) = p\)</span>,</li>
<li><span class="math inline">\(P(Y = 0) = 1 - p\)</span>.</li>
</ul>
<p>Logistic regression models the probability <span class="math inline">\(p\)</span> of success for a single Bernoulli trial.</p>
</section>
<section id="from-bernoulli-to-binomial" class="level3" data-number="10.7.2">
<h3 data-number="10.7.2" class="anchored" data-anchor-id="from-bernoulli-to-binomial"><span class="header-section-number">10.7.2</span> From Bernoulli to Binomial</h3>
<p>Now suppose we repeat a Bernoulli trial <span class="math inline">\(n\)</span> times under identical conditions.</p>
<p>Let:</p>
<ul>
<li><span class="math inline">\(n\)</span> = number of trials,</li>
<li><span class="math inline">\(X\)</span> = number of successes observed.</li>
</ul>
<p>Then <span class="math inline">\(X\)</span> follows a <strong>binomial distribution</strong>, written as:</p>
<p><span class="math display">\[
X \sim \text{Binomial}(n, p)
\]</span></p>
<p>The binomial distribution gives the probability of observing exactly <span class="math inline">\(k\)</span> successes out of <span class="math inline">\(n\)</span> trials:</p>
<p><span class="math display">\[
P(X = k) = \binom{n}{k} p^k (1 - p)^{n - k}
\]</span></p>
<p>Here:</p>
<ul>
<li><span class="math inline">\(\binom{n}{k}\)</span> counts the number of ways to choose <span class="math inline">\(k\)</span> successes from <span class="math inline">\(n\)</span> trials,</li>
<li><span class="math inline">\(p^k\)</span> represents the probability of <span class="math inline">\(k\)</span> successes,</li>
<li><span class="math inline">\((1 - p)^{n - k}\)</span> represents the probability of <span class="math inline">\(n - k\)</span> failures.</li>
</ul>
</section>
<section id="interpreting-the-binomial-distribution" class="level3" data-number="10.7.3">
<h3 data-number="10.7.3" class="anchored" data-anchor-id="interpreting-the-binomial-distribution"><span class="header-section-number">10.7.3</span> Interpreting the Binomial Distribution</h3>
<p>The binomial distribution answers questions such as:</p>
<blockquote class="blockquote">
<p><em>If the probability of success is</em> <span class="math inline">\(p\)</span>, how likely am I to observe <span class="math inline">\(k\)</span> successes out of <span class="math inline">\(n\)</span> attempts?</p>
</blockquote>
<p>For example:</p>
<ul>
<li>If a student has a 60% chance of answering any question correctly,</li>
<li>And they answer 10 independent questions,</li>
</ul>
<p>the binomial distribution tells us how likely it is they will get exactly 6 correct, 7 correct, or any other number.</p>
<p>As <span class="math inline">\(n\)</span> increases:</p>
<ul>
<li>The distribution becomes more concentrated around its average,</li>
<li>Random variation still exists, but extreme outcomes become less likely.</li>
</ul>
</section>
<section id="mean-and-variability" class="level3" data-number="10.7.4">
<h3 data-number="10.7.4" class="anchored" data-anchor-id="mean-and-variability"><span class="header-section-number">10.7.4</span> Mean and Variability</h3>
<p>The binomial distribution has two important summary measures:</p>
<section id="expected-number-of-successes" class="level4" data-number="10.7.4.1">
<h4 data-number="10.7.4.1" class="anchored" data-anchor-id="expected-number-of-successes"><span class="header-section-number">10.7.4.1</span> Expected number of successes</h4>
<p><span class="math display">\[
\mathbb{E}(X) = np
\]</span></p>
<p>This represents the <strong>average number of successes</strong> we would expect if we repeated the experiment many times.</p>
</section>
<section id="variance" class="level4" data-number="10.7.4.2">
<h4 data-number="10.7.4.2" class="anchored" data-anchor-id="variance"><span class="header-section-number">10.7.4.2</span> Variance</h4>
<p><span class="math display">\[
\text{Var}(X) = np(1 - p)
\]</span></p>
<p>The variability depends on both:</p>
<ul>
<li>The number of trials <span class="math inline">\(n\)</span>,</li>
<li>How uncertain the outcome is (largest when <span class="math inline">\(p = 0.5\)</span>).</li>
</ul>
</section>
</section>
<section id="why-the-binomial-distribution-matters-for-logistic-regression" class="level3" data-number="10.7.5">
<h3 data-number="10.7.5" class="anchored" data-anchor-id="why-the-binomial-distribution-matters-for-logistic-regression"><span class="header-section-number">10.7.5</span> Why the Binomial Distribution Matters for Logistic Regression</h3>
<p>Logistic regression is built on the binomial distribution.</p>
<ul>
<li>Each observation is treated as a Bernoulli trial,</li>
<li>The probability of success <span class="math inline">\(p_i\)</span> can vary across observations,</li>
<li>The logit link connects <span class="math inline">\(p_i\)</span> to a linear predictor.</li>
</ul>
<p>Rather than modelling the outcome directly, logistic regression models the <strong>probability parameter</strong> of a binomial process:</p>
<p><span class="math display">\[
Y_i \sim \text{Bernoulli}(p_i)
\]</span></p>
<p><span class="math display">\[
\text{logit}(p_i) = \beta_0 + \beta_1 X_{i1} + \cdots + \beta_k X_{ik}
\]</span></p>
<p>In this way:</p>
<ul>
<li>The binomial distribution provides the probabilistic foundation,</li>
<li>The logistic model explains how predictors influence the probability of success.</li>
</ul>
</section>
</section>
<section id="extending-to-r-from-lm-to-glm" class="level2" data-number="10.8">
<h2 data-number="10.8" class="anchored" data-anchor-id="extending-to-r-from-lm-to-glm"><span class="header-section-number">10.8</span> Extending to R: From <code>lm()</code> to <code>glm()</code></h2>
<p>Up to this point, we have fitted models in R using the <code>lm()</code> function. This function is designed for <strong>linear regression</strong>, where the outcome variable is continuous and normally distributed, and where predictions can take any real value.</p>
<p>However, when our outcome is <strong>binary</strong> (such as pass/fail, win/loss, success/failure), linear regression is no longer appropriate. As we have seen, modelling probabilities directly with a linear model can lead to predicted values outside the valid range of 0 to 1.</p>
<p>To handle binary outcomes properly, R provides a more general modelling function: <code>glm()</code>.</p>
<section id="generalised-linear-models-glms" class="level3" data-number="10.8.1">
<h3 data-number="10.8.1" class="anchored" data-anchor-id="generalised-linear-models-glms"><span class="header-section-number">10.8.1</span> Generalised Linear Models (GLMs)</h3>
<p>The <code>glm()</code> function fits a <strong>generalised linear model</strong>. A GLM has three components:</p>
<ol type="1">
<li><p><strong>A random component</strong><br>
This specifies the distribution of the outcome variable (e.g.&nbsp;normal, binomial).</p></li>
<li><p><strong>A systematic component</strong><br>
This is the linear predictor: <span class="math display">\[
\eta = \beta_0 + \beta_1 X_1 + \cdots + \beta_k X_k
\]</span></p></li>
<li><p><strong>A link function</strong><br>
This connects the mean of the outcome distribution to the linear predictor.</p></li>
</ol>
<p>Logistic regression is a special case of a GLM.</p>
</section>
<section id="logistic-regression-in-r" class="level3" data-number="10.8.2">
<h3 data-number="10.8.2" class="anchored" data-anchor-id="logistic-regression-in-r"><span class="header-section-number">10.8.2</span> Logistic Regression in R</h3>
<p>For logistic regression:</p>
<ul>
<li>The outcome follows a <strong>binomial distribution</strong></li>
<li>The link function is the <strong>logit</strong></li>
<li>The model is fitted using <code>glm()</code> with the <code>family</code> argument</li>
</ul>
<p>The basic syntax is:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> outcome <span class="sc">~</span> predictor,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> binomial,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> your_data</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>Here, <code>family = binomial</code> tells R two things:</p>
<ul>
<li>The outcome is binary (or binomially distributed)</li>
<li>The logit link function should be used by default</li>
</ul>
</section>
<section id="comparing-lm-to-glm" class="level3" data-number="10.8.3">
<h3 data-number="10.8.3" class="anchored" data-anchor-id="comparing-lm-to-glm"><span class="header-section-number">10.8.3</span> Comparing <code>lm()</code> to <code>glm()</code></h3>
<p>It is helpful to see how similar the two functions look:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear regression</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> y <span class="sc">~</span> x1 <span class="sc">+</span> x2, </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> your_data</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic regression</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> y <span class="sc">~</span> x1 <span class="sc">+</span> x2,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df, </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> binomial</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>The formula syntax is identical. The key difference is that glm() requires us to specify the distribution of the outcome via the family argument.</p>
<p>Although the syntax looks similar, the models behave very differently:</p>
<ul>
<li><p>lm() models the outcome directly:</p>
<p><span class="math inline">\(Y=\beta_0+ \beta_1X\)</span></p></li>
<li><p>glm() with <code>family = binomial</code> models the log-odds of success:</p>
<p><span class="math inline">\(\text{logit}(p)=\beta_0+ \beta_1X\)</span></p></li>
</ul>
<p>Internally, glm():</p>
<ul>
<li>Estimates coefficients on the log-odds scale</li>
<li>Uses the anti-logit function to convert fitted values back into probabilities</li>
<li>Guarantees that predicted probabilities lie between 0 and 1</li>
</ul>
</section>
</section>
<section id="a-worked-example" class="level2" data-number="10.9">
<h2 data-number="10.9" class="anchored" data-anchor-id="a-worked-example"><span class="header-section-number">10.9</span> A worked Example</h2>
<p>Suppose we wanted to build a model to predict distance ran (km) based on fitness level. A study was conducted which involved 12 adults. Suppose each participant completed a fitness test where higher scores represent greater levels of fitness. Each participant was then asked to run as far as they could in one session (assume under a controlled testing environment).</p>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-31a5024a{}.cl-319eed56{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-31a16e3c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-31a187b4{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187b5{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187b6{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187be{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187bf{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187c8{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187c9{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187d2{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187d3{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187d4{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187dc{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-31a187dd{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-31a5024a"><thead><tr style="overflow-wrap:break-word;"><th class="cl-31a187b4"><p class="cl-31a16e3c"><span class="cl-319eed56">ID</span></p></th><th class="cl-31a187b5"><p class="cl-31a16e3c"><span class="cl-319eed56">Fitness</span></p></th><th class="cl-31a187b6"><p class="cl-31a16e3c"><span class="cl-319eed56">Distance</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-31a187be"><p class="cl-31a16e3c"><span class="cl-319eed56">1</span></p></td><td class="cl-31a187bf"><p class="cl-31a16e3c"><span class="cl-319eed56">1</span></p></td><td class="cl-31a187c8"><p class="cl-31a16e3c"><span class="cl-319eed56">10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187c9"><p class="cl-31a16e3c"><span class="cl-319eed56">2</span></p></td><td class="cl-31a187d2"><p class="cl-31a16e3c"><span class="cl-319eed56">3</span></p></td><td class="cl-31a187d3"><p class="cl-31a16e3c"><span class="cl-319eed56">2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187c9"><p class="cl-31a16e3c"><span class="cl-319eed56">3</span></p></td><td class="cl-31a187d2"><p class="cl-31a16e3c"><span class="cl-319eed56">5</span></p></td><td class="cl-31a187d3"><p class="cl-31a16e3c"><span class="cl-319eed56">14</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187be"><p class="cl-31a16e3c"><span class="cl-319eed56">4</span></p></td><td class="cl-31a187bf"><p class="cl-31a16e3c"><span class="cl-319eed56">10</span></p></td><td class="cl-31a187c8"><p class="cl-31a16e3c"><span class="cl-319eed56">8</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187c9"><p class="cl-31a16e3c"><span class="cl-319eed56">5</span></p></td><td class="cl-31a187d2"><p class="cl-31a16e3c"><span class="cl-319eed56">13</span></p></td><td class="cl-31a187d3"><p class="cl-31a16e3c"><span class="cl-319eed56">10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187be"><p class="cl-31a16e3c"><span class="cl-319eed56">6</span></p></td><td class="cl-31a187bf"><p class="cl-31a16e3c"><span class="cl-319eed56">15</span></p></td><td class="cl-31a187c8"><p class="cl-31a16e3c"><span class="cl-319eed56">7</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187be"><p class="cl-31a16e3c"><span class="cl-319eed56">7</span></p></td><td class="cl-31a187bf"><p class="cl-31a16e3c"><span class="cl-319eed56">17</span></p></td><td class="cl-31a187c8"><p class="cl-31a16e3c"><span class="cl-319eed56">16</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187be"><p class="cl-31a16e3c"><span class="cl-319eed56">8</span></p></td><td class="cl-31a187bf"><p class="cl-31a16e3c"><span class="cl-319eed56">20</span></p></td><td class="cl-31a187c8"><p class="cl-31a16e3c"><span class="cl-319eed56">10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187be"><p class="cl-31a16e3c"><span class="cl-319eed56">9</span></p></td><td class="cl-31a187bf"><p class="cl-31a16e3c"><span class="cl-319eed56">21</span></p></td><td class="cl-31a187c8"><p class="cl-31a16e3c"><span class="cl-319eed56">12</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187c9"><p class="cl-31a16e3c"><span class="cl-319eed56">10</span></p></td><td class="cl-31a187d2"><p class="cl-31a16e3c"><span class="cl-319eed56">14</span></p></td><td class="cl-31a187d3"><p class="cl-31a16e3c"><span class="cl-319eed56">13</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187be"><p class="cl-31a16e3c"><span class="cl-319eed56">11</span></p></td><td class="cl-31a187bf"><p class="cl-31a16e3c"><span class="cl-319eed56">25</span></p></td><td class="cl-31a187c8"><p class="cl-31a16e3c"><span class="cl-319eed56">7</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-31a187d4"><p class="cl-31a16e3c"><span class="cl-319eed56">12</span></p></td><td class="cl-31a187dc"><p class="cl-31a16e3c"><span class="cl-319eed56">30</span></p></td><td class="cl-31a187dd"><p class="cl-31a16e3c"><span class="cl-319eed56">17</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>We could visualise this with a scatterplot and trendline:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="10-Logistic-regression_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Suppose we also had information on whether or not the participants belonged to a running squad. And instead of examining distance covered, we were predicting squad membership (where Non-squad members are denoted with 0s and Squad members are denoted with 1s):</p>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-3251309c{}.cl-324b7e40{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-324da1a2{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-324db55c{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db566{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db567{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db568{width:1.33in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db570{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db571{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db57a{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db57b{width:1.33in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db57c{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db584{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db585{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db58e{width:1.33in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db58f{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db590{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db598{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-324db599{width:1.33in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-3251309c"><thead><tr style="overflow-wrap:break-word;"><th class="cl-324db55c"><p class="cl-324da1a2"><span class="cl-324b7e40">ID</span></p></th><th class="cl-324db566"><p class="cl-324da1a2"><span class="cl-324b7e40">Fitness</span></p></th><th class="cl-324db567"><p class="cl-324da1a2"><span class="cl-324b7e40">Distance</span></p></th><th class="cl-324db568"><p class="cl-324da1a2"><span class="cl-324b7e40">Squad Member</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-324db570"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td><td class="cl-324db571"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td><td class="cl-324db57a"><p class="cl-324da1a2"><span class="cl-324b7e40">10</span></p></td><td class="cl-324db57b"><p class="cl-324da1a2"><span class="cl-324b7e40">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db57c"><p class="cl-324da1a2"><span class="cl-324b7e40">2</span></p></td><td class="cl-324db584"><p class="cl-324da1a2"><span class="cl-324b7e40">3</span></p></td><td class="cl-324db585"><p class="cl-324da1a2"><span class="cl-324b7e40">2</span></p></td><td class="cl-324db58e"><p class="cl-324da1a2"><span class="cl-324b7e40">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db57c"><p class="cl-324da1a2"><span class="cl-324b7e40">3</span></p></td><td class="cl-324db584"><p class="cl-324da1a2"><span class="cl-324b7e40">5</span></p></td><td class="cl-324db585"><p class="cl-324da1a2"><span class="cl-324b7e40">14</span></p></td><td class="cl-324db58e"><p class="cl-324da1a2"><span class="cl-324b7e40">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db570"><p class="cl-324da1a2"><span class="cl-324b7e40">4</span></p></td><td class="cl-324db571"><p class="cl-324da1a2"><span class="cl-324b7e40">10</span></p></td><td class="cl-324db57a"><p class="cl-324da1a2"><span class="cl-324b7e40">8</span></p></td><td class="cl-324db57b"><p class="cl-324da1a2"><span class="cl-324b7e40">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db57c"><p class="cl-324da1a2"><span class="cl-324b7e40">5</span></p></td><td class="cl-324db584"><p class="cl-324da1a2"><span class="cl-324b7e40">13</span></p></td><td class="cl-324db585"><p class="cl-324da1a2"><span class="cl-324b7e40">10</span></p></td><td class="cl-324db58e"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db570"><p class="cl-324da1a2"><span class="cl-324b7e40">6</span></p></td><td class="cl-324db571"><p class="cl-324da1a2"><span class="cl-324b7e40">15</span></p></td><td class="cl-324db57a"><p class="cl-324da1a2"><span class="cl-324b7e40">7</span></p></td><td class="cl-324db57b"><p class="cl-324da1a2"><span class="cl-324b7e40">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db570"><p class="cl-324da1a2"><span class="cl-324b7e40">7</span></p></td><td class="cl-324db571"><p class="cl-324da1a2"><span class="cl-324b7e40">17</span></p></td><td class="cl-324db57a"><p class="cl-324da1a2"><span class="cl-324b7e40">16</span></p></td><td class="cl-324db57b"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db570"><p class="cl-324da1a2"><span class="cl-324b7e40">8</span></p></td><td class="cl-324db571"><p class="cl-324da1a2"><span class="cl-324b7e40">20</span></p></td><td class="cl-324db57a"><p class="cl-324da1a2"><span class="cl-324b7e40">10</span></p></td><td class="cl-324db57b"><p class="cl-324da1a2"><span class="cl-324b7e40">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db570"><p class="cl-324da1a2"><span class="cl-324b7e40">9</span></p></td><td class="cl-324db571"><p class="cl-324da1a2"><span class="cl-324b7e40">21</span></p></td><td class="cl-324db57a"><p class="cl-324da1a2"><span class="cl-324b7e40">12</span></p></td><td class="cl-324db57b"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db57c"><p class="cl-324da1a2"><span class="cl-324b7e40">10</span></p></td><td class="cl-324db584"><p class="cl-324da1a2"><span class="cl-324b7e40">14</span></p></td><td class="cl-324db585"><p class="cl-324da1a2"><span class="cl-324b7e40">13</span></p></td><td class="cl-324db58e"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db570"><p class="cl-324da1a2"><span class="cl-324b7e40">11</span></p></td><td class="cl-324db571"><p class="cl-324da1a2"><span class="cl-324b7e40">25</span></p></td><td class="cl-324db57a"><p class="cl-324da1a2"><span class="cl-324b7e40">7</span></p></td><td class="cl-324db57b"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-324db58f"><p class="cl-324da1a2"><span class="cl-324b7e40">12</span></p></td><td class="cl-324db590"><p class="cl-324da1a2"><span class="cl-324b7e40">30</span></p></td><td class="cl-324db598"><p class="cl-324da1a2"><span class="cl-324b7e40">17</span></p></td><td class="cl-324db599"><p class="cl-324da1a2"><span class="cl-324b7e40">1</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Because Squad member only has 0s and 1s, out plot will look something like:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="10-Logistic-regression_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>And therefore, we can fit a logitic regression model to this data:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="10-Logistic-regression_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>In R, we would use the <code>glm()</code> function to fit this model:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> Squad <span class="sc">~</span> Fitness,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_sprint2,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> binomial</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = Squad ~ Fitness, family = binomial, data = df_sprint2)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)  -3.6789     2.2948  -1.603   0.1089  
Fitness       0.2528     0.1465   1.726   0.0844 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 16.636  on 11  degrees of freedom
Residual deviance: 10.342  on 10  degrees of freedom
AIC: 14.342

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
</div>
</div>
<section id="making-predictions" class="level3" data-number="10.9.1">
<h3 data-number="10.9.1" class="anchored" data-anchor-id="making-predictions"><span class="header-section-number">10.9.1</span> Making Predictions</h3>
<p>We can use this output to interpret the linear predictor component in a similar way to how we have done previously (i.e.&nbsp;use the estimate column to determine our coefficients):</p>
<p><span class="math display">\[\eta=-3.68+0.25(\text{Fitness})\]</span></p>
<p>And we can use the properties of the logit model to calculate the probability of each person belonging to a running squad, based upon this model.</p>
<p><span class="math display">\[
\begin{aligned}
p &amp;= \frac{e^{\eta}}{1 + e^{\eta}} \\
&amp;= \frac{e^{-3.68+0.25(\text{Fitness})}}{1 + e^{-3.68+0.25(\text{Fitness})}} \\
\end{aligned}
\]</span></p>
<p>And if we apply this to our original data:</p>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-32d06952{}.cl-32c9e744{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-32cc5f2e{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-32cc7540{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc754a{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc754b{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7554{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7555{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc755e{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc755f{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7568{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7569{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7572{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7573{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7574{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc757c{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc757d{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7586{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7587{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7588{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7589{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7590{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-32cc7591{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-32d06952"><thead><tr style="overflow-wrap:break-word;"><th class="cl-32cc7540"><p class="cl-32cc5f2e"><span class="cl-32c9e744">ID</span></p></th><th class="cl-32cc754a"><p class="cl-32cc5f2e"><span class="cl-32c9e744">Fitness</span></p></th><th class="cl-32cc754b"><p class="cl-32cc5f2e"><span class="cl-32c9e744">Distance</span></p></th><th class="cl-32cc7554"><p class="cl-32cc5f2e"><span class="cl-32c9e744">Squad</span></p></th><th class="cl-32cc7555"><p class="cl-32cc5f2e"><span class="cl-32c9e744">p</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-32cc755e"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc755f"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc7568"><p class="cl-32cc5f2e"><span class="cl-32c9e744">10</span></p></td><td class="cl-32cc7569"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0</span></p></td><td class="cl-32cc7572"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.031</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc755e"><p class="cl-32cc5f2e"><span class="cl-32c9e744">2</span></p></td><td class="cl-32cc755f"><p class="cl-32cc5f2e"><span class="cl-32c9e744">3</span></p></td><td class="cl-32cc7568"><p class="cl-32cc5f2e"><span class="cl-32c9e744">2</span></p></td><td class="cl-32cc7569"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0</span></p></td><td class="cl-32cc7572"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.051</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc755e"><p class="cl-32cc5f2e"><span class="cl-32c9e744">3</span></p></td><td class="cl-32cc755f"><p class="cl-32cc5f2e"><span class="cl-32c9e744">5</span></p></td><td class="cl-32cc7568"><p class="cl-32cc5f2e"><span class="cl-32c9e744">14</span></p></td><td class="cl-32cc7569"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0</span></p></td><td class="cl-32cc7572"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.081</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc755e"><p class="cl-32cc5f2e"><span class="cl-32c9e744">4</span></p></td><td class="cl-32cc755f"><p class="cl-32cc5f2e"><span class="cl-32c9e744">10</span></p></td><td class="cl-32cc7568"><p class="cl-32cc5f2e"><span class="cl-32c9e744">8</span></p></td><td class="cl-32cc7569"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0</span></p></td><td class="cl-32cc7572"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.235</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc755e"><p class="cl-32cc5f2e"><span class="cl-32c9e744">5</span></p></td><td class="cl-32cc755f"><p class="cl-32cc5f2e"><span class="cl-32c9e744">13</span></p></td><td class="cl-32cc7568"><p class="cl-32cc5f2e"><span class="cl-32c9e744">10</span></p></td><td class="cl-32cc7569"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc7572"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.394</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc7573"><p class="cl-32cc5f2e"><span class="cl-32c9e744">6</span></p></td><td class="cl-32cc7574"><p class="cl-32cc5f2e"><span class="cl-32c9e744">15</span></p></td><td class="cl-32cc757c"><p class="cl-32cc5f2e"><span class="cl-32c9e744">7</span></p></td><td class="cl-32cc757d"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0</span></p></td><td class="cl-32cc7586"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.517</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc755e"><p class="cl-32cc5f2e"><span class="cl-32c9e744">7</span></p></td><td class="cl-32cc755f"><p class="cl-32cc5f2e"><span class="cl-32c9e744">17</span></p></td><td class="cl-32cc7568"><p class="cl-32cc5f2e"><span class="cl-32c9e744">16</span></p></td><td class="cl-32cc7569"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc7572"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.639</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc7573"><p class="cl-32cc5f2e"><span class="cl-32c9e744">8</span></p></td><td class="cl-32cc7574"><p class="cl-32cc5f2e"><span class="cl-32c9e744">20</span></p></td><td class="cl-32cc757c"><p class="cl-32cc5f2e"><span class="cl-32c9e744">10</span></p></td><td class="cl-32cc757d"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0</span></p></td><td class="cl-32cc7586"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.789</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc7573"><p class="cl-32cc5f2e"><span class="cl-32c9e744">9</span></p></td><td class="cl-32cc7574"><p class="cl-32cc5f2e"><span class="cl-32c9e744">21</span></p></td><td class="cl-32cc757c"><p class="cl-32cc5f2e"><span class="cl-32c9e744">12</span></p></td><td class="cl-32cc757d"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc7586"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.828</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc755e"><p class="cl-32cc5f2e"><span class="cl-32c9e744">10</span></p></td><td class="cl-32cc755f"><p class="cl-32cc5f2e"><span class="cl-32c9e744">14</span></p></td><td class="cl-32cc7568"><p class="cl-32cc5f2e"><span class="cl-32c9e744">13</span></p></td><td class="cl-32cc7569"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc7572"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.455</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc7573"><p class="cl-32cc5f2e"><span class="cl-32c9e744">11</span></p></td><td class="cl-32cc7574"><p class="cl-32cc5f2e"><span class="cl-32c9e744">25</span></p></td><td class="cl-32cc757c"><p class="cl-32cc5f2e"><span class="cl-32c9e744">7</span></p></td><td class="cl-32cc757d"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc7586"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.929</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-32cc7587"><p class="cl-32cc5f2e"><span class="cl-32c9e744">12</span></p></td><td class="cl-32cc7588"><p class="cl-32cc5f2e"><span class="cl-32c9e744">30</span></p></td><td class="cl-32cc7589"><p class="cl-32cc5f2e"><span class="cl-32c9e744">17</span></p></td><td class="cl-32cc7590"><p class="cl-32cc5f2e"><span class="cl-32c9e744">1</span></p></td><td class="cl-32cc7591"><p class="cl-32cc5f2e"><span class="cl-32c9e744">0.979</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Now depending on what threshold we use, we might classify these probabilities differently (see Chapter 9). As an example, if we used a threshold of 0.50:</p>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-330ebbb2{}.cl-3308e1ce{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-330b61a6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-330b76dc{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b76dd{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b76e6{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b76f0{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b76f1{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b76f2{width:1.317in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b76fa{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b76fb{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7704{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7705{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7706{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7707{width:1.317in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b770e{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b770f{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7710{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7718{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7719{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-330b7722{width:1.317in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-330ebbb2"><thead><tr style="overflow-wrap:break-word;"><th class="cl-330b76dc"><p class="cl-330b61a6"><span class="cl-3308e1ce">ID</span></p></th><th class="cl-330b76dd"><p class="cl-330b61a6"><span class="cl-3308e1ce">Fitness</span></p></th><th class="cl-330b76e6"><p class="cl-330b61a6"><span class="cl-3308e1ce">Distance</span></p></th><th class="cl-330b76f0"><p class="cl-330b61a6"><span class="cl-3308e1ce">Squad</span></p></th><th class="cl-330b76f1"><p class="cl-330b61a6"><span class="cl-3308e1ce">p</span></p></th><th class="cl-330b76f2"><p class="cl-330b61a6"><span class="cl-3308e1ce">Classification</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">10</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">0</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.031</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">2</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">3</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">2</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">0</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.051</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">3</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">5</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">14</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">0</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.081</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">4</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">10</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">8</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">0</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.235</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">5</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">13</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">10</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.394</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">6</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">15</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">7</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">0</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.517</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">7</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">17</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">16</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.639</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">8</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">20</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">10</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">0</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.789</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">9</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">21</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">12</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.828</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">10</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">14</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">13</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.455</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b76fa"><p class="cl-330b61a6"><span class="cl-3308e1ce">11</span></p></td><td class="cl-330b76fb"><p class="cl-330b61a6"><span class="cl-3308e1ce">25</span></p></td><td class="cl-330b7704"><p class="cl-330b61a6"><span class="cl-3308e1ce">7</span></p></td><td class="cl-330b7705"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b7706"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.929</span></p></td><td class="cl-330b7707"><p class="cl-330b61a6"><span class="cl-3308e1ce">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-330b770e"><p class="cl-330b61a6"><span class="cl-3308e1ce">12</span></p></td><td class="cl-330b770f"><p class="cl-330b61a6"><span class="cl-3308e1ce">30</span></p></td><td class="cl-330b7710"><p class="cl-330b61a6"><span class="cl-3308e1ce">17</span></p></td><td class="cl-330b7718"><p class="cl-330b61a6"><span class="cl-3308e1ce">1</span></p></td><td class="cl-330b7719"><p class="cl-330b61a6"><span class="cl-3308e1ce">0.979</span></p></td><td class="cl-330b7722"><p class="cl-330b61a6"><span class="cl-3308e1ce">1 = Squad</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>Overall, the model did a pretty good job - correctly classifying all participants except ID 5 and ID 10, and would have resulted in the following confusion matrix:</p>
<center>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>           Actual
Pred        Squad Non-Squad
  Squad         4         2
  Non-Squad     2         4</code></pre>
</div>
</div>
</center>
<p>In this case:</p>
<ul>
<li>Out of 6 ‘Squad’ predictions, 4 were correct and 2 were incorrect</li>
<li>Out of 6 ‘Non-Squad’ predictions, 4 were correct and 2 were incorrect</li>
</ul>
<p>This means that the FPR and FNR would both be 0.3333, and the overall accuracy would be 0.6667.</p>
</section>
<section id="explaining-the-regression-coefficients" class="level3" data-number="10.9.2">
<h3 data-number="10.9.2" class="anchored" data-anchor-id="explaining-the-regression-coefficients"><span class="header-section-number">10.9.2</span> Explaining the Regression Coefficients</h3>
<p>In logistic regression, the estimated coefficients do <strong>not</strong> represent changes in probability. Instead, they represent changes in the <strong>log-odds</strong> of the outcome. To interpret them meaningfully, we must connect the coefficients back to <strong>odds</strong> and <strong>odds ratios</strong>.</p>
<p>Recall that logistic regression models:</p>
<p><span class="math display">\[
\text{logit}(p) = \ln\left(\frac{p}{1-p}\right)
= \beta_0 + \beta_1 X
\]</span></p>
<p>In our model predicting squad selection from fitness:</p>
<p><span class="math display">\[
\text{logit}(p) = -3.68 + 0.25 \times \text{Fitness}
\]</span></p>
<section id="the-intercept" class="level4" data-number="10.9.2.1">
<h4 data-number="10.9.2.1" class="anchored" data-anchor-id="the-intercept"><span class="header-section-number">10.9.2.1</span> The Intercept</h4>
<p>The intercept estimate is:</p>
<p><span class="math display">\[
\hat{\beta}_0 = -3.68
\]</span></p>
<p>This represents the <strong>log-odds of being selected</strong> when Fitness = 0.</p>
<p>Converting this to odds:</p>
<p><span class="math display">\[
\text{Odds} = e^{-3.68} \approx 0.025
\]</span></p>
<p>This means that, at Fitness = 0, the odds of squad selection are approximately <strong>0.025 to 1</strong>, or about <strong>1 selection for every 40 non-selections</strong>.</p>
<p>In practice, Fitness = 0 may not be a meaningful value, so the intercept is often best viewed as a <strong>baseline reference point</strong> rather than a quantity of direct interest.</p>
</section>
<section id="the-fitness-coefficient" class="level4" data-number="10.9.2.2">
<h4 data-number="10.9.2.2" class="anchored" data-anchor-id="the-fitness-coefficient"><span class="header-section-number">10.9.2.2</span> The Fitness Coefficient</h4>
<p>The estimated coefficient for Fitness is:</p>
<p><span class="math display">\[
\hat{\beta}_1 = 0.25
\]</span></p>
<p>This means:</p>
<blockquote class="blockquote">
<p>For a one-unit increase in Fitness, the <strong>log-odds</strong> of squad selection increase by 0.25.</p>
</blockquote>
<p>Because log-odds are not intuitive, we usually exponentiate this coefficient to obtain an <strong>odds ratio</strong>.</p>
</section>
<section id="odds-ratios" class="level4" data-number="10.9.2.3">
<h4 data-number="10.9.2.3" class="anchored" data-anchor-id="odds-ratios"><span class="header-section-number">10.9.2.3</span> Odds Ratios</h4>
<p>Exponentiating the Fitness coefficient gives:</p>
<p><span class="math display">\[
\text{Odds ratio} = e^{0.25} \approx 1.28
\]</span></p>
<p>This has a clear interpretation:</p>
<blockquote class="blockquote">
<p>For each one-unit increase in Fitness, the odds of being selected for the squad are multiplied by <strong>1.28</strong>.</p>
</blockquote>
<p>Equivalently:</p>
<ul>
<li>The odds increase by <strong>28%</strong> for every additional unit of Fitness.</li>
</ul>
<p>This interpretation holds regardless of the current probability — odds ratios describe <strong>multiplicative changes in odds</strong>, not additive changes in probability.</p>
</section>
<section id="why-probabilities-change-non-linearly" class="level4" data-number="10.9.2.4">
<h4 data-number="10.9.2.4" class="anchored" data-anchor-id="why-probabilities-change-non-linearly"><span class="header-section-number">10.9.2.4</span> Why Probabilities Change Non-Linearly</h4>
<p>Although the coefficient implies a constant multiplicative change in odds, the corresponding change in <strong>probability</strong> depends on where you are on the logistic curve:</p>
<ul>
<li>When probabilities are near 0.5, small changes in Fitness lead to <strong>large changes in probability</strong></li>
<li>When probabilities are near 0 or 1, the same change in Fitness has a <strong>smaller effect on probability</strong></li>
</ul>
<p>This explains why logistic regression produces an S-shaped curve rather than a straight line.</p>
</section>
<section id="statistical-significance" class="level4" data-number="10.9.2.5">
<h4 data-number="10.9.2.5" class="anchored" data-anchor-id="statistical-significance"><span class="header-section-number">10.9.2.5</span> Statistical Significance</h4>
<p>The p-value for Fitness is:</p>
<p><span class="math display">\[
p = 0.084
\]</span></p>
<p>This provides <strong>weak evidence</strong> that Fitness is associated with squad selection at the 10% level, but not strong evidence at the conventional 5% level. Importantly, statistical significance does not affect how the coefficient is interpreted — it only affects our confidence in the estimated relationship.</p>
</section>
</section>
<section id="multiple-predictors" class="level3" data-number="10.9.3">
<h3 data-number="10.9.3" class="anchored" data-anchor-id="multiple-predictors"><span class="header-section-number">10.9.3</span> Multiple Predictors</h3>
<p>Let’s have a look at what happens when we include an additional predictor to the model. Here we want to see if we can predict Squad membership based upon Fitness Score and Distance ran:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> Squad <span class="sc">~</span> Fitness <span class="sc">+</span> Distance,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_sprint2,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> binomial</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = Squad ~ Fitness + Distance, family = binomial, 
    data = df_sprint2)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)  -9.9075     6.3359  -1.564    0.118  
Fitness       0.3016     0.1773   1.700    0.089 .
Distance      0.5197     0.4155   1.251    0.211  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 16.6355  on 11  degrees of freedom
Residual deviance:  7.7566  on  9  degrees of freedom
AIC: 13.757

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
</div>
</div>
<p>From the output:</p>
<p><span class="math display">\[\eta=-9.91+0.30(\text{Fitness})+0.52(\text{Distance})\]</span></p>
<p>And therefore:</p>
<p><span class="math display">\[
p = \frac{e^{-9.91+0.30(\text{Fitness})+0.52(\text{Distance})}}{1 + e^{-9.91+0.30(\text{Fitness})+0.52(\text{Distance})}}
\]</span></p>
<p>If we once again use a threshold of 0.50, the predictions become:</p>
<div class="cell">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-334c346a{}.cl-33464b68{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-33488568{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-33489b8e{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489b98{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489ba2{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489ba3{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489ba4{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bac{width:1.317in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bad{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bae{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bb6{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bb7{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bc0{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bc1{width:1.317in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bca{width:0.455in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bcb{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bcc{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bd4{width:0.727in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bd5{width:0.668in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-33489bde{width:1.317in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-334c346a"><thead><tr style="overflow-wrap:break-word;"><th class="cl-33489b8e"><p class="cl-33488568"><span class="cl-33464b68">ID</span></p></th><th class="cl-33489b98"><p class="cl-33488568"><span class="cl-33464b68">Fitness</span></p></th><th class="cl-33489ba2"><p class="cl-33488568"><span class="cl-33464b68">Distance</span></p></th><th class="cl-33489ba3"><p class="cl-33488568"><span class="cl-33464b68">Squad</span></p></th><th class="cl-33489ba4"><p class="cl-33488568"><span class="cl-33464b68">p</span></p></th><th class="cl-33489bac"><p class="cl-33488568"><span class="cl-33464b68">Classification</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">10</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">0</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.012</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">2</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">3</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">2</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">0</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.000</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">3</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">5</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">14</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">0</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.244</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">4</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">10</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">8</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">0</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.060</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">5</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">13</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">10</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.308</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">6</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">15</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">7</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">0</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.146</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">0 = Non-Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">7</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">17</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">16</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.971</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">8</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">20</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">10</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">0</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.784</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">9</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">21</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">12</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.933</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">10</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">14</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">13</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.741</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bad"><p class="cl-33488568"><span class="cl-33464b68">11</span></p></td><td class="cl-33489bae"><p class="cl-33488568"><span class="cl-33464b68">25</span></p></td><td class="cl-33489bb6"><p class="cl-33488568"><span class="cl-33464b68">7</span></p></td><td class="cl-33489bb7"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bc0"><p class="cl-33488568"><span class="cl-33464b68">0.774</span></p></td><td class="cl-33489bc1"><p class="cl-33488568"><span class="cl-33464b68">1 = Squad</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-33489bca"><p class="cl-33488568"><span class="cl-33464b68">12</span></p></td><td class="cl-33489bcb"><p class="cl-33488568"><span class="cl-33464b68">30</span></p></td><td class="cl-33489bcc"><p class="cl-33488568"><span class="cl-33464b68">17</span></p></td><td class="cl-33489bd4"><p class="cl-33488568"><span class="cl-33464b68">1</span></p></td><td class="cl-33489bd5"><p class="cl-33488568"><span class="cl-33464b68">1.000</span></p></td><td class="cl-33489bde"><p class="cl-33488568"><span class="cl-33464b68">1 = Squad</span></p></td></tr></tbody></table></div>
</div>
</div>
<p>This time around, our confusion matrix is:</p>
<center>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>           Actual
Pred        Squad Non-Squad
  Squad         5         1
  Non-Squad     1         5</code></pre>
</div>
</div>
</center>
<p>Overall, by adding Distance to our model:</p>
<ul>
<li>Out of 6 ‘Squad’ predictions, 5 were correct and 1 was incorrect</li>
<li>Out of 6 ‘Non-Squad’ predictions, 5 were correct and 1 were incorrect</li>
</ul>
<p>This means that the FPR and FNR would both be 0.1667, and the overall accuracy would be 0.8333 (these metrics improved from the previous model which only used Fitness as a predictor).</p>
</section>
</section>
<section id="practice-with-r" class="level2" data-number="10.10">
<h2 data-number="10.10" class="anchored" data-anchor-id="practice-with-r"><span class="header-section-number">10.10</span> Practice with R</h2>
<p>Let us use the same data from the previous Chapter (<code>timor.RDS</code>), but instead of running a LPM, we will construct a logistic regression.</p>
<section id="download-the-data" class="level3" data-number="10.10.1">
<h3 data-number="10.10.1" class="anchored" data-anchor-id="download-the-data"><span class="header-section-number">10.10.1</span> Download the data</h3>
<p>The data set is stored in a R data format file named <code>timor.RDS</code>. Note: this is not an excel file, so you won’t be able to open it in Excel. Begin by downloading the file and moving it your working directory.</p>
<center>
<div class="cell">
<div class="cell-output-display">
<button class="btn btn-success" onclick="
    async function downloadFile(event) {
      event.preventDefault();
      try {
        const response = await fetch('data:application/octet-stream;base64,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');
        if (!response.ok) throw new Error('Network response failed');
        const blob = await response.blob();
        const blobUrl = window.URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = blobUrl;
        a.download = 'timor.RDS';
        a.style.display = 'none';
        document.body.appendChild(a);
        a.dispatchEvent(new MouseEvent('click'));
        document.body.removeChild(a);
        setTimeout(() => {
          window.URL.revokeObjectURL(blobUrl);
        }, 100);
        return false;
      } catch (error) {
        console.error('Download failed:', error);
        alert('Download failed. Please try again.');
      }
    }
    downloadFile(event);
  "><i class="fa fa-save"></i> timor.RDS</button>
</div>
</div>
</center>
</section>
<section id="load-the-data-in-rstudio" class="level3" data-number="10.10.2">
<h3 data-number="10.10.2" class="anchored" data-anchor-id="load-the-data-in-rstudio"><span class="header-section-number">10.10.2</span> Load the data in RStudio</h3>
<p>Next, let us load the data into our working environment in RStudio. Because the data file is a .RDS file, we will use the <code>readRDS()</code> function. In the code below, I am saving the file as ‘timor’.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>timor <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"timor.RDS"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="load-the-tidyverse" class="level3" data-number="10.10.3">
<h3 data-number="10.10.3" class="anchored" data-anchor-id="load-the-tidyverse"><span class="header-section-number">10.10.3</span> Load the tidyverse</h3>
<p>Use the <code>library()</code> function to load the tidyverse package. This will provide us with all of the tools we need to complete this exercise.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="inspect-the-data" class="level3" data-number="10.10.4">
<h3 data-number="10.10.4" class="anchored" data-anchor-id="inspect-the-data"><span class="header-section-number">10.10.4</span> Inspect the data</h3>
<p>Run the <code>str()</code> function to display the structure of the data frame:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(timor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   5916 obs. of  5 variables:
 $ poor     : num  0 1 0 0 0 1 1 0 0 0 ...
 $ hhsize   : int  7 7 8 2 4 10 5 1 6 4 ...
 $ district : chr  "Aileu" "Baucau" "Dili" "Viqueque" ...
 $ urban    : num  1 0 1 0 0 1 0 0 1 0 ...
 $ dirtfloor: num  0 0 0 1 0 0 1 1 1 1 ...</code></pre>
</div>
</div>
</div>
</div>
<p>There are 5916 observations and five variables:</p>
<ul>
<li><code>poor</code>: whether a household officially classifies as poor; 1 indicates poor, and 0 otherwise</li>
<li><code>hhsize</code>: household size</li>
<li><code>district</code>: the district where a household locates</li>
<li><code>urban</code>: whether a household is from an urban area; 1indicates yes, and 0 otherwise (rural)</li>
<li><code>dirtfloor</code>: whether a household has a dirt floor; 1 indicates yes and 0 otherwise</li>
</ul>
</section>
<section id="training-and-testing-sets" class="level3" data-number="10.10.5">
<h3 data-number="10.10.5" class="anchored" data-anchor-id="training-and-testing-sets"><span class="header-section-number">10.10.5</span> Training and Testing sets</h3>
<p>Let’s now create the model that can be used to predict whether a household is poor, based on these four characteristics.</p>
<p>First, we will split the data into two subsets: a training set and test set. There are 5916 households in the data set. It’s common practice to <strong>randomly</strong> split your data into the training and testing sets, however in this exercise we will specify the first 70% (4141) households as training data, and the remaining 30% for testing.</p>
<p>We can use the <code>slice()</code> function to slice our data into parts. Remember that our data set has 5916 households. therefore:</p>
<ul>
<li>House 1 to House 4141 will be allocated to the training set</li>
<li>House 4142 to House 5916 will be allocated to the testing set</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> timor <span class="sc">|&gt;</span> <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4141</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> timor <span class="sc">|&gt;</span> <span class="fu">slice</span>(<span class="dv">4142</span><span class="sc">:</span><span class="dv">5916</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>To make sure you have done this correctly, check that you have two objects (train and test) stored in your global environment.</p>
</section>
<section id="building-the-model" class="level3" data-number="10.10.6">
<h3 data-number="10.10.6" class="anchored" data-anchor-id="building-the-model"><span class="header-section-number">10.10.6</span> Building the model</h3>
<p>Last time, we fitted a LPM to this data. This time around, we will fit a logistic regression. We will run both models so that we can compare the results.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># lpm</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>timor_lpm <span class="ot">&lt;-</span> <span class="fu">lm</span>(poor <span class="sc">~</span> hhsize <span class="sc">+</span> district <span class="sc">+</span> urban <span class="sc">+</span> dirtfloor, train)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># logistic</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>timor_logreg <span class="ot">&lt;-</span> <span class="fu">glm</span>(poor <span class="sc">~</span> hhsize <span class="sc">+</span> district <span class="sc">+</span> urban <span class="sc">+</span> dirtfloor, train, <span class="at">family =</span> <span class="st">'binomial'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>We can now use the <code>summary()</code> function to inspect this model</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = poor ~ hhsize + district + urban + dirtfloor, family = "binomial", 
    data = train)

Coefficients:
                 Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)      -4.98564    0.24862 -20.053  &lt; 2e-16 ***
hhsize            0.54931    0.02065  26.602  &lt; 2e-16 ***
districtAinaro    0.29263    0.24920   1.174 0.240292    
districtBaucau   -0.10712    0.23589  -0.454 0.649766    
districtBobonaro  1.31676    0.23389   5.630 1.81e-08 ***
districtCovalima  1.62966    0.23847   6.834 8.27e-12 ***
districtDili      0.24797    0.22753   1.090 0.275788    
districtErmera    0.56752    0.23570   2.408 0.016049 *  
districtLautem   -0.18987    0.25665  -0.740 0.459437    
districtLiqui?a   0.90086    0.24171   3.727 0.000194 ***
districtManatuto  0.37061    0.25518   1.452 0.146404    
districtManufahi  0.89162    0.24643   3.618 0.000297 ***
districtOecussi   1.93570    0.23325   8.299  &lt; 2e-16 ***
districtViqueque -0.25373    0.24754  -1.025 0.305367    
urban            -0.77748    0.09572  -8.122 4.57e-16 ***
dirtfloor         1.24735    0.09150  13.632  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 5212.4  on 4140  degrees of freedom
Residual deviance: 3824.8  on 4125  degrees of freedom
AIC: 3856.8

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="making-predictions-1" class="level3" data-number="10.10.7">
<h3 data-number="10.10.7" class="anchored" data-anchor-id="making-predictions-1"><span class="header-section-number">10.10.7</span> Making predictions</h3>
<p>Similar to last time, let’s use the <code>predict()</code> function on our two models with the test data:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note: By default, predict() returns fitted values on the log-odds scale. Setting <code>type = "response"</code> applies the anti-logit transformation, converting log-odds into probabilities between 0 and 1.</p>
</div>
</div>
</section>
<section id="combining-actual-and-predictions" class="level3" data-number="10.10.8">
<h3 data-number="10.10.8" class="anchored" data-anchor-id="combining-actual-and-predictions"><span class="header-section-number">10.10.8</span> Combining Actual and Predictions</h3>
<p>We can now create a data set that combines our actual values (the <code>poor</code> variable) with the <code>predictions</code> we generated in the previous step.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>res_lpm <span class="ot">&lt;-</span> </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  test <span class="sc">|&gt;</span> </span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">preds =</span> predictions_lpm) <span class="sc">|&gt;</span> </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">class =</span> <span class="fu">ifelse</span>(preds <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"poor"</span>, <span class="st">"not poor"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">actual =</span> <span class="fu">ifelse</span>(poor <span class="sc">==</span> <span class="dv">1</span>, <span class="st">"poor"</span>, <span class="st">"not poor"</span>))</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>res_logreg <span class="ot">&lt;-</span> </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  test <span class="sc">|&gt;</span> </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">preds =</span> predictions_logreg) <span class="sc">|&gt;</span> </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">class =</span> <span class="fu">ifelse</span>(preds <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"poor"</span>, <span class="st">"not poor"</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">actual =</span> <span class="fu">ifelse</span>(poor <span class="sc">==</span> <span class="dv">1</span>, <span class="st">"poor"</span>, <span class="st">"not poor"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="reorder-factor-levels-optional" class="level3" data-number="10.10.9">
<h3 data-number="10.10.9" class="anchored" data-anchor-id="reorder-factor-levels-optional"><span class="header-section-number">10.10.9</span> Reorder factor levels (optional)</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>res_lpm <span class="ot">&lt;-</span> </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  res_lpm <span class="sc">|&gt;</span> </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">actual =</span> <span class="fu">fct_relevel</span>(actual, <span class="st">"poor"</span>, <span class="st">"not poor"</span>),</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">class =</span> <span class="fu">fct_relevel</span>(class, <span class="st">"poor"</span>, <span class="st">"not poor"</span>))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>res_logreg <span class="ot">&lt;-</span> </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  res_logreg <span class="sc">|&gt;</span> </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">actual =</span> <span class="fu">fct_relevel</span>(actual, <span class="st">"poor"</span>, <span class="st">"not poor"</span>),</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">class =</span> <span class="fu">fct_relevel</span>(class, <span class="st">"poor"</span>, <span class="st">"not poor"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="confusion-matrix" class="level3" data-number="10.10.10">
<h3 data-number="10.10.10" class="anchored" data-anchor-id="confusion-matrix"><span class="header-section-number">10.10.10</span> Confusion Matrix</h3>
<p>We can now use the <code>table()</code> function to create a confusion matrix of our actual and predicted classifications:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
R Code
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Prediction =</span> res_lpm<span class="sc">$</span>class, <span class="at">Actual =</span> res_lpm<span class="sc">$</span>actual)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Actual
Prediction poor not poor
  poor      287      128
  not poor  313     1047</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Prediction =</span> res_logreg<span class="sc">$</span>class, <span class="at">Actual =</span> res_logreg<span class="sc">$</span>actual)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Actual
Prediction poor not poor
  poor      294      133
  not poor  306     1042</code></pre>
</div>
</div>
</div>
</div>
<p>From our output above, we can calculate the False Positive rate for both models are:</p>
<p><span class="math display">\[FPR_{LPM}=\frac{128}{128+1047}=0.1089\]</span></p>
<p><span class="math display">\[FPR_{LogReg}=\frac{133}{133+1042}=0.1132\]</span></p>
<p>Likewise, the False Negative rates are:</p>
<p><span class="math display">\[FPR_{LPM}=\frac{313}{313+287}=0.5217\]</span></p>
<p><span class="math display">\[FPR_{LogReg}=\frac{306}{306+294}=0.51\]</span></p>
<p>Here, the logistic regression model had a lower false negative rate (FNR) compared to the linear probability model (0.51 versus 0.52). However, it also exhibited a higher false positive rate (FPR) (0.113 versus 0.109). With that said, the preference would still be to use the logistic regression model because it is theoretically appropriate for binary outcomes, guarantees valid predicted probabilities between 0 and 1, and models the relationship between predictors and the outcome in a statistically principled way. The differences in FPR and FNR are also dependent on the chosen classification threshold; by adjusting this threshold, logistic regression allows practitioners to explicitly trade off between false positives and false negatives in a way that the linear probability model does not naturally support. As a result, even if performance metrics are similar or mixed at a single threshold, logistic regression provides a more flexible and reliable framework for both prediction and inference in classification problems.</p>
</section>
</section>
<section id="summary" class="level2" data-number="10.11">
<h2 data-number="10.11" class="anchored" data-anchor-id="summary"><span class="header-section-number">10.11</span> Summary</h2>
<p>In this chapter, we introduced <strong>logistic regression</strong> as a modelling approach designed specifically for <strong>binary outcomes</strong> (such as win/loss, pass/fail, or squad/non-squad). We began by revisiting the linear probability model (LPM) and highlighting why it can be problematic for classification tasks: linear models can produce predicted values below 0 or above 1, and the assumed linear relationship between predictors and probabilities is often unrealistic. Logistic regression resolves these issues by ensuring predicted probabilities always remain in the valid range, while still allowing us to build a model using familiar regression ideas.</p>
<p>The key shift was moving from <strong>probabilities</strong> to <strong>odds</strong> and then to <strong>log-odds (logits)</strong>. Odds compare the chance of success to the chance of failure, and the logit transformation maps probabilities from the bounded interval <span class="math inline">\((0,1)\)</span> to the entire real line <span class="math inline">\((-\infty, +\infty)\)</span>. This is crucial because it allows us to write a regression-style equation on the log-odds scale, while the <strong>anti-logit (inverse logit)</strong> converts model predictions back into probabilities. Graphically, this produces the familiar <strong>S-shaped logistic curve</strong>, which captures an important real-world feature: changes in predictors tend to have the biggest impact on probability when the outcome is uncertain (around <span class="math inline">\(p=0.5\)</span>), and smaller impact when the outcome is already very unlikely or very likely.</p>
<p>We also linked logistic regression to its probabilistic foundation: the <strong>binomial distribution</strong>. Each observation in a logistic regression model can be viewed as a Bernoulli trial (0 or 1), and the model estimates the probability of success for each observation. This framework provides a principled way to model classification problems, and it explains why logistic regression is so widely used in business, health, economics, and data science.</p>
<p>Finally, we extended these ideas to R. While we used <code>lm()</code> for linear regression, logistic regression is fitted using <code>glm()</code> with <code>family = binomial</code>. In our sprint example, we used the fitted model to generate predicted probabilities, classify individuals using a probability threshold, and evaluate model performance using a confusion matrix. We also introduced coefficient interpretation: logistic regression coefficients describe changes in <strong>log-odds</strong>, and exponentiating them gives <strong>odds ratios</strong>, which describe multiplicative changes in odds. In the next chapter, we will build on this foundation by looking more closely at prediction quality, threshold choice, and how to assess and compare classification models.</p>
</section>
<section id="exercises" class="level2" data-number="10.12">
<h2 data-number="10.12" class="anchored" data-anchor-id="exercises"><span class="header-section-number">10.12</span> Exercises</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 1
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose we are modelling whether a student passes an exam (1 = pass, 0 = fail).</p>
<ol type="a">
<li>Explain two reasons why a linear probability model (LPM) fitted using lm() is not ideal for this task.</li>
<li>Briefly explain how logistic regression addresses these issues.</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click for Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="a">
<li>Two key problems with the linear probability model are:
<ol type="1">
<li>Invalid predicted probabilities: Linear regression can produce predicted values below 0 or above 1, which are not meaningful probabilities.</li>
<li>Unrealistic functional form: The LPM assumes a linear relationship between predictors and probability, even though probability changes are often non-linear (e.g., diminishing returns at high or low probabilities).</li>
</ol></li>
<li>Logistic regression addresses these issues by:
<ul>
<li>Modelling the log-odds of the outcome as a linear function of predictors, rather than modelling probability directly.</li>
<li>Using the anti-logit transformation, which guarantees that predicted probabilities always lie between 0 and 1 and naturally produces an S-shaped (logistic) curve.</li>
</ul></li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 2
</div>
</div>
<div class="callout-body-container callout-body">
<p>A basketball player has a probability of making a free throw of <span class="math inline">\(p=0.75\)</span>.</p>
<ol type="a">
<li>Calculate and interpret the odds of making the free throw.</li>
<li>Calculate the log-odds (logit).</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click for Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>a.</strong></p>
<p><span class="math display">\[Odds=\frac{p}{1-p}=\frac{0.75}{0.25}=3\]</span></p>
<p>The odds are 3 to 1 in favour of success (making a free throw).</p>
<p><strong>b.</strong></p>
<p><span class="math display">\[\text{logit}(p)=ln(Odds)=ln(3)=1.10\]</span></p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 3
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider the logistic regression model:</p>
<p><span class="math display">\[\text{logit}(p)=-2.5+0.4X\]</span></p>
<ol type="a">
<li>Interpret the coefficient 0.4 in terms of log-odds.</li>
<li>Convert this coefficient to an odds ratio and interpret it.</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click for Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>a.</strong></p>
<p>The coefficient 0.4 means that for a one-unit increase in X, the log-odds of success increase by 0.4.</p>
<p><strong>b.</strong></p>
<p>The odds ratio is <span class="math inline">\(e^{0.4}=1.49\)</span>. For each one-unit increase in X, the odds of success are multiplied by approximately 1.49 (an increase of about 49%).</p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 4
</div>
</div>
<div class="callout-body-container callout-body">
<p>A logistic regression model for squad selection is:</p>
<p><span class="math display">\[\text{logit}(p)=-3+0.5(Fitness)\]</span></p>
<ol type="a">
<li>Calculate the probability of selection when Fitness = 6.</li>
<li>Would this individual be classified as a squad member if a threshold of 0.4 were used?</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click for Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>a.</strong></p>
<p>First calculate the linear predictor:</p>
<p><span class="math display">\[\eta=-3+0.5(6)=0\]</span></p>
<p>Convert to probability using the anti-logit:</p>
<p><span class="math display">\[p=\frac{e^0}{1+e^0}=\frac{1}{2}=0.5\]</span></p>
<p><strong>b.</strong></p>
<p>Using a threshold of 0.4, this individual would be classified as a squad member, since <span class="math inline">\(p \ge0.4\)</span></p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question 5
</div>
</div>
<div class="callout-body-container callout-body">
<p>You are given a data frame df containing a binary outcome Pass (0 = fail, 1 = pass) and a predictor Hours.</p>
<ol type="a">
<li>Write the R code to fit a logistic regression model predicting Pass from Hours.</li>
<li>Write the R code to obtain predicted probabilities from this model.</li>
<li>Explain why type = “response” is needed.</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click for Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>a.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  Pass <span class="sc">~</span> Hours,</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df,</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> binomial</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>b.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(model, <span class="at">type =</span> <span class="st">"response"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>c.</strong></p>
<p>By default, predict() returns fitted values on the log-odds scale. Setting type = “response” applies the anti-logit transformation, converting log-odds into probabilities between 0 and 1.</p>
</div>
</div>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./09-Classification-and-prediction.html" class="pagination-link" aria-label="Classification and Prediction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Classification and Prediction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>